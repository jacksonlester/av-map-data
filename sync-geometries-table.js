#!/usr/bin/env node

/**
 * Sync Geometries Table with Storage Bucket
 *
 * This script ensures all GeoJSON files in the storage bucket are registered
 * in the service_area_geometries table with proper metadata.
 *
 * Usage:
 *   STAGING=true node sync-geometries-table.js  (syncs staging)
 *   node sync-geometries-table.js               (syncs production)
 */

import { createClient } from '@supabase/supabase-js'
import { config } from 'dotenv'

// Load .env file
if (!process.env.GITHUB_ACTIONS) {
  config()
}

const supabaseUrl = process.env.SUPABASE_URL
const supabaseServiceKey = process.env.SUPABASE_SERVICE_KEY || process.env.SUPABASE_ANON_KEY

if (!supabaseUrl || !supabaseServiceKey) {
  console.error('âŒ Missing required environment variables!')
  console.error('Please set SUPABASE_URL and SUPABASE_SERVICE_KEY in .env')
  process.exit(1)
}

const supabase = createClient(supabaseUrl, supabaseServiceKey)

// Determine environment
const isStaging = process.env.STAGING === 'true'
const bucket = isStaging ? 'staging-service-area-boundaries' : 'service-area-boundaries'
const table = isStaging ? 'service_area_geometries_staging' : 'service_area_geometries'
const env = isStaging ? 'STAGING' : 'PRODUCTION'

console.log(`ğŸŒ Environment: ${env}`)
console.log(`ğŸ“¦ Bucket: ${bucket}`)
console.log(`ğŸ“‹ Table: ${table}\n`)

async function syncGeometriesTable() {
  // Step 1: List all files in storage bucket
  console.log('ğŸ“¡ Fetching files from storage bucket...')
  const { data: files, error: listError } = await supabase.storage
    .from(bucket)
    .list('', { limit: 1000 })

  if (listError) {
    console.error('âŒ Error listing files:', listError)
    process.exit(1)
  }

  const geojsonFiles = files.filter(f => f.name.endsWith('.geojson'))
  console.log(`   Found ${geojsonFiles.length} geometry files in bucket\n`)

  // Step 2: Get existing entries in database table
  console.log('ğŸ“Š Fetching existing entries from database...')
  const { data: existingEntries, error: dbError } = await supabase
    .from(table)
    .select('geometry_name')

  if (dbError) {
    console.error('âŒ Error fetching from database:', dbError)
    process.exit(1)
  }

  const existingNames = new Set(existingEntries?.map(e => e.geometry_name) || [])
  console.log(`   Found ${existingNames.size} existing entries in table\n`)

  // Step 3: Insert missing entries
  console.log('ğŸ“ Syncing table with storage...')

  let inserted = 0
  let skipped = 0
  let failed = 0

  for (const file of geojsonFiles) {
    const geometryName = file.name.replace('.geojson', '')

    if (existingNames.has(geometryName)) {
      console.log(`   â­ï¸  ${geometryName} (already exists)`)
      skipped++
      continue
    }

    // Create public URL
    const { data: { publicUrl } } = supabase.storage
      .from(bucket)
      .getPublicUrl(file.name)

    // Insert into table
    const { error: insertError } = await supabase
      .from(table)
      .insert({
        geometry_name: geometryName,
        display_name: geometryName.replace(/-/g, ' '),
        storage_url: publicUrl,
        file_size: file.metadata?.size || 0,
        created_at: file.created_at || new Date().toISOString()
      })

    if (insertError) {
      console.error(`   âŒ ${geometryName}: ${insertError.message}`)
      failed++
    } else {
      console.log(`   âœ… ${geometryName} (inserted)`)
      inserted++
    }
  }

  console.log('\nğŸ“Š Sync Summary:')
  console.log(`   âœ… Inserted: ${inserted}`)
  console.log(`   â­ï¸  Skipped (existing): ${skipped}`)
  console.log(`   âŒ Failed: ${failed}`)
  console.log(`   ğŸ“ Total files: ${geojsonFiles.length}`)

  if (failed === 0) {
    console.log('\nâœ… Geometries table synced successfully!')
    console.log('\nğŸ“ Next steps:')
    console.log(`   Run: ${isStaging ? 'STAGING=true ' : ''}node rebuild-cache.js`)
  } else {
    console.log('\nâš ï¸  Some entries failed to insert. Please check errors above.')
    process.exit(1)
  }
}

syncGeometriesTable().catch(error => {
  console.error('âŒ Fatal error:', error)
  process.exit(1)
})
